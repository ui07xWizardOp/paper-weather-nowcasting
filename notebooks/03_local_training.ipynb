{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 03_local_training.ipynb - ULTRA FAST VERSION\n",
                "\n",
                "**Optimizations:**\n",
                "- Mixed Precision (AMP) - 2x faster\n",
                "- cudnn.benchmark - 10-15% faster\n",
                "- Fast batch loading\n",
                "- GPU verification\n",
                "\n",
                "**Expected: ~2-5 min per epoch on T4**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Device: cpu\n",
                        "⚠️ WARNING: Running on CPU! This will be VERY SLOW!\n",
                        "Enable GPU: Runtime → Change runtime type → GPU\n",
                        "✓ Mixed Precision (AMP) enabled\n",
                        "Data dir: /content/data/batched\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipython-input-2013606280.py:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
                        "  scaler = GradScaler()\n",
                        "/usr/local/lib/python3.12/dist-packages/torch/cuda/amp/grad_scaler.py:31: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
                        "  super().__init__(\n"
                    ]
                }
            ],
            "source": [
                "# Cell 1: Setup with optimizations\n",
                "import os, gc, glob, time\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "# CRITICAL: Verify GPU\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Device: {device}')\n",
                "if device.type != 'cuda':\n",
                "    print('⚠️ WARNING: Running on CPU! This will be VERY SLOW!')\n",
                "    print('Enable GPU: Runtime → Change runtime type → GPU')\n",
                "else:\n",
                "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
                "    print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
                "    torch.backends.cudnn.benchmark = True\n",
                "    print('✓ cudnn.benchmark enabled')\n",
                "\n",
                "# Mixed Precision\n",
                "from torch.cuda.amp import autocast, GradScaler\n",
                "scaler = GradScaler()\n",
                "print('✓ Mixed Precision (AMP) enabled')\n",
                "\n",
                "# Paths\n",
                "NOTEBOOK_DIR = os.getcwd()\n",
                "PROJECT_ROOT = os.path.dirname(NOTEBOOK_DIR) if NOTEBOOK_DIR.endswith('notebooks') else NOTEBOOK_DIR\n",
                "DATA_DIR = os.path.join(PROJECT_ROOT, 'data', 'batched')\n",
                "CHECKPOINT_DIR = os.path.join(PROJECT_ROOT, 'checkpoints')\n",
                "FIGURES_DIR = os.path.join(PROJECT_ROOT, 'figures')\n",
                "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
                "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
                "print(f'Data dir: {DATA_DIR}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train: 0 files × 16 = 0 batches\n",
                        "Val: 0 files × 16 = 0 batches\n",
                        "\n",
                        "Benchmarking data loading...\n",
                        "50 batches in 0.00s (0.0ms/batch)\n"
                    ]
                }
            ],
            "source": [
                "# Cell 2: FAST Data Loading\n",
                "BATCH_SIZE = 32\n",
                "\n",
                "def get_batch_files(split):\n",
                "    split_dir = os.path.join(DATA_DIR, split)\n",
                "    x_files = sorted(glob.glob(os.path.join(split_dir, 'X_batch_*.npy')))\n",
                "    y_files = sorted(glob.glob(os.path.join(split_dir, 'Y_batch_*.npy')))\n",
                "    return x_files, y_files\n",
                "\n",
                "def batch_generator(split, batch_size=BATCH_SIZE, shuffle=False):\n",
                "    x_files, y_files = get_batch_files(split)\n",
                "    file_indices = list(range(len(x_files)))\n",
                "    if shuffle:\n",
                "        np.random.shuffle(file_indices)\n",
                "    \n",
                "    for idx in file_indices:\n",
                "        X = np.load(x_files[idx])\n",
                "        Y = np.load(y_files[idx])\n",
                "        n = len(X)\n",
                "        indices = np.random.permutation(n) if shuffle else np.arange(n)\n",
                "        \n",
                "        for start in range(0, n, batch_size):\n",
                "            batch_idx = indices[start:start+batch_size]\n",
                "            x = torch.from_numpy(X[batch_idx]).float().permute(0, 1, 4, 2, 3)\n",
                "            y = torch.from_numpy(Y[batch_idx]).float().permute(0, 1, 4, 2, 3)\n",
                "            yield x, y\n",
                "\n",
                "# Verify data and count batches\n",
                "train_files, _ = get_batch_files('train')\n",
                "val_files, _ = get_batch_files('val')\n",
                "SAMPLES_PER_FILE = 500\n",
                "BATCHES_PER_FILE = (SAMPLES_PER_FILE + BATCH_SIZE - 1) // BATCH_SIZE  # ceil division\n",
                "n_train_batches = len(train_files) * BATCHES_PER_FILE\n",
                "n_val_batches = len(val_files) * BATCHES_PER_FILE\n",
                "print(f'Train: {len(train_files)} files × {BATCHES_PER_FILE} = {n_train_batches} batches')\n",
                "print(f'Val: {len(val_files)} files × {BATCHES_PER_FILE} = {n_val_batches} batches')\n",
                "\n",
                "# Quick benchmark\n",
                "print('\\nBenchmarking data loading...')\n",
                "t0 = time.time()\n",
                "for i, (x, y) in enumerate(batch_generator('train')):\n",
                "    if i >= 50:\n",
                "        break\n",
                "print(f'50 batches in {time.time()-t0:.2f}s ({(time.time()-t0)/50*1000:.1f}ms/batch)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: '/content/data/batched/stats.npz'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipython-input-3241781918.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cell 3: Load Stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stats.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variables'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Variables: {variables}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/batched/stats.npz'"
                    ]
                }
            ],
            "source": [
                "# Cell 3: Load Stats\n",
                "stats = np.load(os.path.join(DATA_DIR, 'stats.npz'), allow_pickle=True)\n",
                "mean, std = stats['mean'], stats['std']\n",
                "variables = list(stats['variables'])\n",
                "print(f'Variables: {variables}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 4: Model\n",
                "class ConvLSTMCell(nn.Module):\n",
                "    def __init__(self, input_dim, hidden_dim, kernel_size):\n",
                "        super().__init__()\n",
                "        self.hidden_dim = hidden_dim\n",
                "        self.conv = nn.Conv2d(input_dim + hidden_dim, 4 * hidden_dim,\n",
                "                              kernel_size, padding=kernel_size//2)\n",
                "    def forward(self, x, hidden):\n",
                "        h, c = hidden\n",
                "        gates = self.conv(torch.cat([x, h], dim=1))\n",
                "        i, f, o, g = torch.chunk(gates, 4, dim=1)\n",
                "        c_next = torch.sigmoid(f) * c + torch.sigmoid(i) * torch.tanh(g)\n",
                "        h_next = torch.sigmoid(o) * torch.tanh(c_next)\n",
                "        return h_next, c_next\n",
                "    def init_hidden(self, B, H, W, dev):\n",
                "        return (torch.zeros(B, self.hidden_dim, H, W, device=dev),\n",
                "                torch.zeros(B, self.hidden_dim, H, W, device=dev))\n",
                "\n",
                "class WeatherNowcaster(nn.Module):\n",
                "    def __init__(self, in_ch, hidden_dim, out_ch, n_layers=2):\n",
                "        super().__init__()\n",
                "        self.encoder = nn.ModuleList([ConvLSTMCell(in_ch if i==0 else hidden_dim, hidden_dim, 3) for i in range(n_layers)])\n",
                "        self.decoder = nn.ModuleList([ConvLSTMCell(out_ch if i==0 else hidden_dim, hidden_dim, 3) for i in range(n_layers)])\n",
                "        self.out_conv = nn.Conv2d(hidden_dim, out_ch, 1)\n",
                "    \n",
                "    def forward(self, x, future_steps):\n",
                "        B, T, C, H, W = x.shape\n",
                "        hidden = [cell.init_hidden(B, H, W, x.device) for cell in self.encoder]\n",
                "        for t in range(T):\n",
                "            inp = x[:, t]\n",
                "            for i, cell in enumerate(self.encoder):\n",
                "                h, c = cell(inp, hidden[i])\n",
                "                hidden[i] = (h, c)\n",
                "                inp = h\n",
                "        \n",
                "        dec_hidden = [(h.clone(), c.clone()) for h, c in hidden]\n",
                "        outputs = []\n",
                "        dec_in = self.out_conv(dec_hidden[-1][0])\n",
                "        for _ in range(future_steps):\n",
                "            for i, cell in enumerate(self.decoder):\n",
                "                h, c = cell(dec_in if i==0 else h, dec_hidden[i])\n",
                "                dec_hidden[i] = (h, c)\n",
                "            dec_in = self.out_conv(h)\n",
                "            outputs.append(dec_in)\n",
                "        return torch.stack(outputs, dim=1)\n",
                "\n",
                "T_IN, T_OUT = 24, 6\n",
                "HIDDEN_DIM = 128\n",
                "\n",
                "model = WeatherNowcaster(2, HIDDEN_DIM, 2, n_layers=2).to(device)\n",
                "print(f'Parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
                "\n",
                "# Benchmark model\n",
                "print('\\nBenchmarking model...')\n",
                "x_test = torch.randn(BATCH_SIZE, T_IN, 2, 31, 41).to(device)\n",
                "torch.cuda.synchronize()\n",
                "t0 = time.time()\n",
                "for _ in range(10):\n",
                "    with autocast():\n",
                "        _ = model(x_test, T_OUT)\n",
                "    torch.cuda.synchronize()\n",
                "print(f'10 forward passes in {time.time()-t0:.2f}s ({(time.time()-t0)/10*1000:.1f}ms/batch)')\n",
                "del x_test\n",
                "torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 5: FAST Training with AMP\n",
                "criterion = nn.MSELoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
                "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
                "\n",
                "NUM_EPOCHS = 50\n",
                "best_val_loss = float('inf')\n",
                "train_losses, val_losses = [], []\n",
                "\n",
                "print(f'Training: {NUM_EPOCHS} epochs, batch={BATCH_SIZE}, hidden={HIDDEN_DIM}')\n",
                "print('=' * 60)\n",
                "\n",
                "for epoch in range(NUM_EPOCHS):\n",
                "    epoch_start = time.time()\n",
                "    \n",
                "    # Train\n",
                "    model.train()\n",
                "    train_loss, n_batches = 0.0, 0\n",
                "    pbar = tqdm(batch_generator('train', BATCH_SIZE, shuffle=True), \n",
                "                total=n_train_batches, desc=f'Epoch {epoch+1} [Train]', leave=False)\n",
                "    \n",
                "    for x, y in pbar:\n",
                "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
                "        optimizer.zero_grad(set_to_none=True)\n",
                "        \n",
                "        with autocast():\n",
                "            out = model(x, T_OUT)\n",
                "            loss = criterion(out, y)\n",
                "        \n",
                "        scaler.scale(loss).backward()\n",
                "        scaler.unscale_(optimizer)\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        \n",
                "        train_loss += loss.item()\n",
                "        n_batches += 1\n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    train_loss /= n_batches\n",
                "    train_losses.append(train_loss)\n",
                "    \n",
                "    # Validate\n",
                "    model.eval()\n",
                "    val_loss, n_val = 0.0, 0\n",
                "    with torch.no_grad():\n",
                "        for x, y in tqdm(batch_generator('val', BATCH_SIZE), total=n_val_batches, \n",
                "                         desc=f'Epoch {epoch+1} [Val]', leave=False):\n",
                "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
                "            with autocast():\n",
                "                val_loss += criterion(model(x, T_OUT), y).item()\n",
                "            n_val += 1\n",
                "    \n",
                "    val_loss /= n_val\n",
                "    val_losses.append(val_loss)\n",
                "    scheduler.step(val_loss)\n",
                "    \n",
                "    epoch_time = time.time() - epoch_start\n",
                "    marker = '★ BEST' if val_loss < best_val_loss else ''\n",
                "    print(f'Epoch {epoch+1:2d} | Train: {train_loss:.6f} | Val: {val_loss:.6f} | Time: {epoch_time:.1f}s {marker}')\n",
                "    \n",
                "    if val_loss < best_val_loss:\n",
                "        best_val_loss = val_loss\n",
                "        torch.save({'model': model.state_dict(), 'val_loss': val_loss}, \n",
                "                   os.path.join(CHECKPOINT_DIR, 'best_model.pth'))\n",
                "    \n",
                "    gc.collect()\n",
                "    torch.cuda.empty_cache()\n",
                "\n",
                "print('=' * 60)\n",
                "print(f'✓ Done! Best val loss: {best_val_loss:.6f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 6: Plot & Save\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.plot(train_losses, label='Train')\n",
                "plt.plot(val_losses, label='Val')\n",
                "plt.xlabel('Epoch'); plt.ylabel('MSE Loss')\n",
                "plt.legend(); plt.grid(alpha=0.3)\n",
                "plt.savefig(os.path.join(FIGURES_DIR, 'training_curve.png'), dpi=150)\n",
                "plt.show()\n",
                "\n",
                "torch.save({\n",
                "    'model_state_dict': model.state_dict(),\n",
                "    'config': {'hidden_dim': HIDDEN_DIM, 'n_layers': 2, 'T_IN': T_IN, 'T_OUT': T_OUT},\n",
                "    'mean': mean, 'std': std, 'variables': variables,\n",
                "    'best_val_loss': best_val_loss\n",
                "}, os.path.join(CHECKPOINT_DIR, 'final_model.pth'))\n",
                "print('Saved final_model.pth')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
