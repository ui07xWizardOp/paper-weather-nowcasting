{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 01_setup_and_download.ipynb\n",
                "\n",
                "**Purpose**: Initialize the project environment and download raw ERA5-Land data.\n",
                "**Runtime**: ~2-4 hours for full download.\n",
                "**Strategy**: Monthly downloads to avoid CDS 'cost limits exceeded' errors.\n",
                "\n",
                "**Note**: If you already have dataset files (`data_0*.nc` or `era5land_*.nc`), skip to the validation cell."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Define Project Root\n",
                "PROJECT_ROOT = '/content/drive/MyDrive/WeatherPaper'\n",
                "print(f\"Project Root: {PROJECT_ROOT}\")\n",
                "\n",
                "!pip install cdsapi xarray netCDF4 pyyaml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import yaml\n",
                "import cdsapi\n",
                "import xarray as xr\n",
                "import glob\n",
                "\n",
                "# Create directories\n",
                "subdirs = ['config', 'data/raw', 'data/processed', 'checkpoints', 'outputs', 'figures']\n",
                "for sd in subdirs:\n",
                "    os.makedirs(os.path.join(PROJECT_ROOT, sd), exist_ok=True)\n",
                "print(\"Directory structure verified.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Config & Credentials"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Scoping\n",
                "scope_config = {\n",
                "    \"region\": {\n",
                "        \"name\": \"Odisha\",\n",
                "        \"north\": 20.0,\n",
                "        \"south\": 17.0,\n",
                "        \"east\": 85.0,\n",
                "        \"west\": 81.0\n",
                "    },\n",
                "    \"time_split\": {\n",
                "        \"train_years\": [2015, 2016, 2017, 2018, 2019, 2020, 2021],\n",
                "        \"val_years\": [2022, 2023],\n",
                "        \"test_years\": [2024, 2025]\n",
                "    }\n",
                "}\n",
                "\n",
                "with open(os.path.join(PROJECT_ROOT, 'config/project_scope.yaml'), 'w') as f:\n",
                "    yaml.dump(scope_config, f)\n",
                "\n",
                "# 2. Variables\n",
                "var_config = {\n",
                "    \"cds_variables\": ['total_precipitation', '2m_temperature', 'mean_sea_level_pressure'],\n",
                "    \"internal_names\": {'total_precipitation': 'tp', '2m_temperature': 't2m', 'mean_sea_level_pressure': 'msl'}\n",
                "}\n",
                "\n",
                "with open(os.path.join(PROJECT_ROOT, 'config/variables.yaml'), 'w') as f:\n",
                "    yaml.dump(var_config, f)\n",
                "\n",
                "# 3. Credentials (Replace with your own key!)\n",
                "cdsapirc_path = os.path.join(os.path.expanduser('~'), '.cdsapirc')\n",
                "url = \"https://cds.climate.copernicus.eu/api\"\n",
                "key = \"YOUR_CDS_API_KEY_HERE\"  # Get from: https://cds.climate.copernicus.eu/user\n",
                "\n",
                "with open(cdsapirc_path, 'w') as f:\n",
                "    f.write(f\"url: {url}\\nkey: {key}\")\n",
                "print(\"Config and Credentials Saved.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Check for Existing Dataset\n",
                "\n",
                "If you already have downloaded files (`data_0*.nc`), you can skip the download."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for existing files\n",
                "raw_dir = os.path.join(PROJECT_ROOT, 'data/raw')\n",
                "\n",
                "# Check various file patterns\n",
                "existing_era5 = glob.glob(os.path.join(raw_dir, \"era5land_*.nc\"))\n",
                "existing_data0 = glob.glob(os.path.join(raw_dir, \"data_0*.nc\"))\n",
                "existing_any = glob.glob(os.path.join(raw_dir, \"*.nc\"))\n",
                "\n",
                "print(f\"Files in {raw_dir}:\")\n",
                "print(f\"  era5land_*.nc: {len(existing_era5)} files\")\n",
                "print(f\"  data_0*.nc: {len(existing_data0)} files\")\n",
                "print(f\"  Total *.nc: {len(existing_any)} files\")\n",
                "\n",
                "if existing_any:\n",
                "    print(\"\\n✓ Dataset files found! You can skip to Section 5 (Validation).\")\n",
                "else:\n",
                "    print(\"\\n⚠ No dataset files found. Run Section 4 to download.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. (Optional) Download ERA5 Data\n",
                "Skip this section if you already have data files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def download_era5_month(year, month, output_folder, region_box):\n",
                "    month_str = f\"{month:02d}\"\n",
                "    output_file = os.path.join(output_folder, f\"era5land_{year}_{month_str}.nc\")\n",
                "    \n",
                "    if os.path.exists(output_file):\n",
                "        if os.path.getsize(output_file) > 1 * 1024 * 1024: # > 1MB check\n",
                "            print(f\"Skipping {year}-{month_str}: Exists.\")\n",
                "            return\n",
                "        else:\n",
                "            print(f\"Redownloading {year}-{month_str}: Too small.\")\n",
                "            os.remove(output_file)\n",
                "\n",
                "    print(f\"Downloading {year}-{month_str}...\")\n",
                "    c = cdsapi.Client()\n",
                "    \n",
                "    c.retrieve(\n",
                "        'reanalysis-era5-land',\n",
                "        {\n",
                "            'format': 'netcdf',\n",
                "            'variable': [\n",
                "                'total_precipitation', '2m_temperature', 'mean_sea_level_pressure',\n",
                "            ],\n",
                "            'year': str(year),\n",
                "            'month': month_str,\n",
                "            'day': [\n",
                "                '01', '02', '03', '04', '05', '06',\n",
                "                '07', '08', '09', '10', '11', '12',\n",
                "                '13', '14', '15', '16', '17', '18',\n",
                "                '19', '20', '21', '22', '23', '24',\n",
                "                '25', '26', '27', '28', '29', '30',\n",
                "                '31',\n",
                "            ],\n",
                "            'time': [\n",
                "                '00:00', '01:00', '02:00', '03:00', '04:00', '05:00',\n",
                "                '06:00', '07:00', '08:00', '09:00', '10:00', '11:00',\n",
                "                '12:00', '13:00', '14:00', '15:00', '16:00', '17:00',\n",
                "                '18:00', '19:00', '20:00', '21:00', '22:00', '23:00',\n",
                "            ],\n",
                "            'area': [\n",
                "                region_box['north'], \n",
                "                region_box['west'], \n",
                "                region_box['south'], \n",
                "                region_box['east'],\n",
                "            ],\n",
                "        },\n",
                "        output_file)\n",
                "    print(f\"Finished {year}-{month_str}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Execute Download (Monthly)\n",
                "# SKIP THIS CELL IF YOU ALREADY HAVE DATA\n",
                "years = range(2015, 2025)\n",
                "months = range(1, 13)\n",
                "raw_dir = os.path.join(PROJECT_ROOT, 'data/raw')\n",
                "region_cfg = scope_config['region']\n",
                "\n",
                "for y in years:\n",
                "    for m in months:\n",
                "        try:\n",
                "            download_era5_month(y, m, raw_dir, region_cfg)\n",
                "        except Exception as e:\n",
                "            print(f\"FAILED {y}-{m}: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Dataset Validation\n",
                "\n",
                "Validate that all NetCDF files are readable and have consistent structure."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validation - Works with both naming conventions\n",
                "raw_dir = os.path.join(PROJECT_ROOT, 'data/raw')\n",
                "\n",
                "# Find all NetCDF files\n",
                "files = sorted(glob.glob(os.path.join(raw_dir, \"*.nc\")))\n",
                "print(f\"Total Files: {len(files)}\")\n",
                "\n",
                "if len(files) == 0:\n",
                "    raise FileNotFoundError(f\"No NetCDF files found in {raw_dir}\")\n",
                "\n",
                "# Validate structure of first 5 files\n",
                "print(\"\\nValidating file structure...\")\n",
                "valid_count = 0\n",
                "issues = []\n",
                "\n",
                "for f in files[:5]:\n",
                "    try:\n",
                "        ds = xr.open_dataset(f)\n",
                "        # Check for time coordinate (could be 'time' or 'valid_time')\n",
                "        has_time = 'time' in ds.coords or 'valid_time' in ds.coords\n",
                "        has_tp = 'tp' in ds.data_vars\n",
                "        \n",
                "        if has_time and has_tp:\n",
                "            valid_count += 1\n",
                "        else:\n",
                "            issues.append(f\"{os.path.basename(f)}: missing time or tp\")\n",
                "        \n",
                "        ds.close()\n",
                "    except Exception as e:\n",
                "        issues.append(f\"{os.path.basename(f)}: {str(e)[:50]}\")\n",
                "\n",
                "print(f\"✓ {valid_count}/5 sample files validated successfully\")\n",
                "\n",
                "if issues:\n",
                "    print(\"\\nIssues found:\")\n",
                "    for iss in issues:\n",
                "        print(f\"  ⚠ {iss}\")\n",
                "else:\n",
                "    print(\"\\n=== ALL VALIDATIONS PASSED ===\")\n",
                "    print(\"You can proceed to 02_preprocessing.ipynb\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Print sample file structure for reference\n",
                "if files:\n",
                "    sample_file = files[0]\n",
                "    print(f\"Sample file: {os.path.basename(sample_file)}\")\n",
                "    print(f\"Size: {os.path.getsize(sample_file)/1e6:.2f} MB\")\n",
                "    \n",
                "    ds = xr.open_dataset(sample_file)\n",
                "    print(f\"\\nCoordinates: {list(ds.coords)}\")\n",
                "    print(f\"Variables: {list(ds.data_vars)}\")\n",
                "    print(f\"Dimensions: {dict(ds.dims)}\")\n",
                "    \n",
                "    # Show time coordinate info\n",
                "    time_coord = 'valid_time' if 'valid_time' in ds.coords else 'time'\n",
                "    if time_coord in ds.coords:\n",
                "        times = ds[time_coord].values\n",
                "        print(f\"\\nTime coordinate: '{time_coord}'\")\n",
                "        print(f\"Time range: {str(times[0])[:19]} to {str(times[-1])[:19]}\")\n",
                "        print(f\"Time steps: {len(times)}\")\n",
                "    \n",
                "    ds.close()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}